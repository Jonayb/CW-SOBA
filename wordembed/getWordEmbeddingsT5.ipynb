{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "getWordEmbeddingsT5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P29NvvnypuRx"
      },
      "source": [
        "# CREATING WORD EMBEDDINGS FOR ONTOLOGY USE\n",
        "# --------------------------------------------------\n",
        "#\n",
        "# Adapted by Jonathan IJbema\n",
        "#\n",
        "#\n",
        "# Transform reviews into T5 wordembeddings and save them in a json-style text file.\n",
        "# 2. Load dataset in special format. Reviews must be separated by ,|,\n",
        "# 3. Remove negations from dataset\n",
        "# 4. Create word embeddings\n",
        "# 5. Save word embeddings to json-style text file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxWKl9MWVT4M",
        "outputId": "d78ef876-b992-4090-f85b-6717ac842323"
      },
      "source": [
        "# Install and import libraries\n",
        "#!pip install transformers\n",
        "\n",
        "import torch\n",
        "from transformers import T5Tokenizer, T5Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "import pprint\n",
        "import sys\n",
        "import json\n",
        "from string import digits\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "print(\"Model choice: T5. Important libraries and models imported.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model choice: T5. Important libraries and models imported.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPXaBY07VT4P",
        "outputId": "72817ee8-983a-425e-c0d7-0ed91d775d14"
      },
      "source": [
        "# Load data for creating word embeddings\n",
        "\n",
        "i=0\n",
        "reviews=[]\n",
        "file = open('DCWEB/data/restData5k.txt', 'r', encoding=\"utf-8\")\n",
        "review = file.read()\n",
        "review = review.replace(\"\\n\", ' ')\n",
        "\n",
        "#Reviews are split on ,|,\n",
        "wrong_review = review.split(\",|,\") \n",
        "for w in wrong_review:\n",
        "    i += 1\n",
        "    reviews.append(w)\n",
        "reviews = reviews[0:1900] # Choose subset from reviews\n",
        "#reviews = sample(reviews, 1600) # Choose random subset from reviews\n",
        "print(\"Number of reviews : \", len(reviews))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of reviews :  1900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzqjTpMBVT4Q",
        "outputId": "d410c2d1-19ec-4d24-b899-819cecfc2087"
      },
      "source": [
        "# Code for removing negation words in same sentence\n",
        "i = 0\n",
        "review = 0\n",
        "sentC=0\n",
        "reviewsNew = []\n",
        "neg = \" not \"\n",
        "neg2 = \" nothing \"\n",
        "neg3 = \"never \"\n",
        "neg4 = \" didn\\'t\"\n",
        "neg5 = \" wouldn\\'t\"\n",
        "neg6 = \" don\\'t\"\n",
        "neg7 = \" can\\'t\"\n",
        "neg8 = \" doesn\\'t\"\n",
        "neg9 = \" coudn't\"\n",
        "case=0\n",
        "for z in reviews:\n",
        "    sent2New = []\n",
        "    sentNew= \"\"\n",
        "    sent = z.split('.')\n",
        "    case = 0\n",
        "    for j in sent:\n",
        "        sent2 = j.split('!')\n",
        "        for l in sent2:\n",
        "            sentC+=1\n",
        "            if (neg in l) or (neg2 in l) or (neg3 in l) or (neg4 in l) or (neg5 in l) or (neg6 in l) or (neg7 in l) or (neg8 in l) or (neg9 in l):\n",
        "                i += 1\n",
        "                sent2.remove(l)\n",
        "                if case == 0:\n",
        "                    review += 1\n",
        "                    case = 1\n",
        "        sent2New.append(\"!\".join(sent2))\n",
        "    #print(sent2New)\n",
        "    sentNew = (\".\".join(sent2New))\n",
        "    reviewsNew.append(str(sentNew))\n",
        "\n",
        "print(\"Number of sentences with negation word:\", i)\n",
        "print(\"Number of reviews with these negation word:\" ,review)\n",
        "print(\"Number of sentences in text: \", sentC)\n",
        "print(\"Number of sentences in text after removing sentences: \", sentC - i )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences with negation word: 846\n",
            "Number of reviews with these negation word: 655\n",
            "Number of sentences in text:  11590\n",
            "Number of sentences in text after removing sentences:  10744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzeRw2jFVT4Q",
        "outputId": "d536a9d2-cf2b-4036-e931-5c07f6ae6074"
      },
      "source": [
        "# Load pre-trained model (weights)\n",
        "#model = T5Model.from_pretrained('t5-base', output_hidden_states = True,)                                #pretrained\n",
        "model = T5Model.from_pretrained('DCWEB/T5finetuned', output_hidden_states = True,)                          #finetuned\n",
        "print(\"T5 model is downloaded.\")\n",
        "\n",
        "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "model.eval()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at DCWEB/T5finetuned were not used when initializing T5Model: ['lm_head.weight']\n",
            "- This IS expected if you are initializing T5Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing T5Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "T5 model is downloaded.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5Model(\n",
              "  (shared): Embedding(32128, 768)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (6): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (8): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (9): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (10): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (11): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (6): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (8): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (9): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (10): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (11): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uut0JqmnVT4R",
        "outputId": "e08b50f7-f01c-48da-cf5c-1bc5c6ef7193"
      },
      "source": [
        "#Create word embeddings\n",
        "start = time.time()\n",
        "intermediate_time = start\n",
        "bert_vectors = []\n",
        "review_counter = 0\n",
        "j = 1\n",
        "#loops over the reviews\n",
        "for rev in reviews:\n",
        "    rev = rev.lower().replace('\\n', '').replace('\\r', '').strip()\n",
        "    update = 20\n",
        "    if review_counter % update == 0:\n",
        "      start_time = intermediate_time\n",
        "      intermediate_time = time.time()\n",
        "      embedding_time = (intermediate_time - start_time)\n",
        "      if review_counter < 40:\n",
        "        average = embedding_time\n",
        "      else:\n",
        "        average = (average*(review_counter/20 - 1) + embedding_time) / (review_counter/20)\n",
        "      ETA = average*(len(reviews)/update-review_counter/update)\n",
        "      print(\"Estimated remaining time: \", str(round(ETA/60, 1)), \" minutes.\")\n",
        "      print(\"Embedding review: \" + str(review_counter))\n",
        "\n",
        "    result = []\n",
        "    tokenized_text = tokenizer.tokenize(rev)\n",
        "    t5tok = tokenizer(rev, return_tensors=\"pt\")\n",
        "    #change to 512 or shorter\n",
        "    if len(tokenized_text)>=512:\n",
        "        del tokenized_text[512:len(tokenized_text)]\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "    segments_ids = [1] * len(tokenized_text)\n",
        "    for word in tokenized_text:\n",
        "        if len(word) == 0 :\n",
        "          print(\"Word with 0 length.\")\n",
        "          continue\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "    segments_tensors = torch.tensor([segments_ids])\n",
        "    with torch.no_grad():\n",
        "        outputs = model.encoder(input_ids=t5tok[\"input_ids\"], attention_mask=t5tok[\"attention_mask\"], return_dict=True)\n",
        "        hidden_states = outputs.hidden_states\n",
        "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "    token_embeddings = token_embeddings.permute(1,0,2)\n",
        "    token_vecs_sum = []\n",
        "    for token in token_embeddings:\n",
        "        sum_vec = torch.sum(token[-4:], dim=0)\n",
        "        token_vecs_sum.append(sum_vec)\n",
        "    token_vecs = hidden_states[-2][0]\n",
        "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "    #get all results for one review and display\n",
        "    # replace with whole vector!\n",
        "    i=0\n",
        "    tok_text = t5tok[\"input_ids\"].tolist()[0]\n",
        "    while i < len(tok_text) - 1:\n",
        "      veccie = [round(vec,4) for vec in token_vecs_sum[i].tolist()]\n",
        "      text = tokenizer.decode(tok_text[i]).strip()\n",
        "      if not text.isalnum():\n",
        "        i += 1\n",
        "        continue\n",
        "      result.append([text, veccie, review_counter])\n",
        "      i += 1\n",
        "    \n",
        "    bert_vectors.append(result)\n",
        "\n",
        "    del result\n",
        "    review_counter+=1\n",
        "\n",
        "end = time.time()\n",
        "print(\"Time: \", end-start, \"s\")\n",
        "print(\"Reviews are tokenized and put into vectors!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimated remaining time:  0.0  minutes.\n",
            "Embedding review: 0\n",
            "Estimated remaining time:  5.0  minutes.\n",
            "Embedding review: 20\n",
            "Estimated remaining time:  4.5  minutes.\n",
            "Embedding review: 40\n",
            "Estimated remaining time:  4.8  minutes.\n",
            "Embedding review: 60\n",
            "Estimated remaining time:  4.7  minutes.\n",
            "Embedding review: 80\n",
            "Estimated remaining time:  4.6  minutes.\n",
            "Embedding review: 100\n",
            "Estimated remaining time:  4.6  minutes.\n",
            "Embedding review: 120\n",
            "Estimated remaining time:  4.5  minutes.\n",
            "Embedding review: 140\n",
            "Estimated remaining time:  4.5  minutes.\n",
            "Embedding review: 160\n",
            "Estimated remaining time:  4.6  minutes.\n",
            "Embedding review: 180\n",
            "Estimated remaining time:  4.6  minutes.\n",
            "Embedding review: 200\n",
            "Estimated remaining time:  4.5  minutes.\n",
            "Embedding review: 220\n",
            "Estimated remaining time:  4.6  minutes.\n",
            "Embedding review: 240\n",
            "Estimated remaining time:  4.4  minutes.\n",
            "Embedding review: 260\n",
            "Estimated remaining time:  4.4  minutes.\n",
            "Embedding review: 280\n",
            "Estimated remaining time:  4.3  minutes.\n",
            "Embedding review: 300\n",
            "Estimated remaining time:  4.3  minutes.\n",
            "Embedding review: 320\n",
            "Estimated remaining time:  4.3  minutes.\n",
            "Embedding review: 340\n",
            "Estimated remaining time:  4.3  minutes.\n",
            "Embedding review: 360\n",
            "Estimated remaining time:  4.2  minutes.\n",
            "Embedding review: 380\n",
            "Estimated remaining time:  4.2  minutes.\n",
            "Embedding review: 400\n",
            "Estimated remaining time:  4.1  minutes.\n",
            "Embedding review: 420\n",
            "Estimated remaining time:  4.1  minutes.\n",
            "Embedding review: 440\n",
            "Estimated remaining time:  4.1  minutes.\n",
            "Embedding review: 460\n",
            "Estimated remaining time:  4.0  minutes.\n",
            "Embedding review: 480\n",
            "Estimated remaining time:  4.0  minutes.\n",
            "Embedding review: 500\n",
            "Estimated remaining time:  3.9  minutes.\n",
            "Embedding review: 520\n",
            "Estimated remaining time:  3.9  minutes.\n",
            "Embedding review: 540\n",
            "Estimated remaining time:  3.8  minutes.\n",
            "Embedding review: 560\n",
            "Estimated remaining time:  3.8  minutes.\n",
            "Embedding review: 580\n",
            "Estimated remaining time:  3.7  minutes.\n",
            "Embedding review: 600\n",
            "Estimated remaining time:  3.6  minutes.\n",
            "Embedding review: 620\n",
            "Estimated remaining time:  3.6  minutes.\n",
            "Embedding review: 640\n",
            "Estimated remaining time:  3.5  minutes.\n",
            "Embedding review: 660\n",
            "Estimated remaining time:  3.5  minutes.\n",
            "Embedding review: 680\n",
            "Estimated remaining time:  3.4  minutes.\n",
            "Embedding review: 700\n",
            "Estimated remaining time:  3.4  minutes.\n",
            "Embedding review: 720\n",
            "Estimated remaining time:  3.3  minutes.\n",
            "Embedding review: 740\n",
            "Estimated remaining time:  3.3  minutes.\n",
            "Embedding review: 760\n",
            "Estimated remaining time:  3.2  minutes.\n",
            "Embedding review: 780\n",
            "Estimated remaining time:  3.2  minutes.\n",
            "Embedding review: 800\n",
            "Estimated remaining time:  3.1  minutes.\n",
            "Embedding review: 820\n",
            "Estimated remaining time:  3.1  minutes.\n",
            "Embedding review: 840\n",
            "Estimated remaining time:  3.0  minutes.\n",
            "Embedding review: 860\n",
            "Estimated remaining time:  2.9  minutes.\n",
            "Embedding review: 880\n",
            "Estimated remaining time:  2.9  minutes.\n",
            "Embedding review: 900\n",
            "Estimated remaining time:  2.8  minutes.\n",
            "Embedding review: 920\n",
            "Estimated remaining time:  2.8  minutes.\n",
            "Embedding review: 940\n",
            "Estimated remaining time:  2.7  minutes.\n",
            "Embedding review: 960\n",
            "Estimated remaining time:  2.7  minutes.\n",
            "Embedding review: 980\n",
            "Estimated remaining time:  2.6  minutes.\n",
            "Embedding review: 1000\n",
            "Estimated remaining time:  2.6  minutes.\n",
            "Embedding review: 1020\n",
            "Estimated remaining time:  2.5  minutes.\n",
            "Embedding review: 1040\n",
            "Estimated remaining time:  2.5  minutes.\n",
            "Embedding review: 1060\n",
            "Estimated remaining time:  2.4  minutes.\n",
            "Embedding review: 1080\n",
            "Estimated remaining time:  2.4  minutes.\n",
            "Embedding review: 1100\n",
            "Estimated remaining time:  2.3  minutes.\n",
            "Embedding review: 1120\n",
            "Estimated remaining time:  2.2  minutes.\n",
            "Embedding review: 1140\n",
            "Estimated remaining time:  2.2  minutes.\n",
            "Embedding review: 1160\n",
            "Estimated remaining time:  2.1  minutes.\n",
            "Embedding review: 1180\n",
            "Estimated remaining time:  2.1  minutes.\n",
            "Embedding review: 1200\n",
            "Estimated remaining time:  2.0  minutes.\n",
            "Embedding review: 1220\n",
            "Estimated remaining time:  2.0  minutes.\n",
            "Embedding review: 1240\n",
            "Estimated remaining time:  1.9  minutes.\n",
            "Embedding review: 1260\n",
            "Estimated remaining time:  1.8  minutes.\n",
            "Embedding review: 1280\n",
            "Estimated remaining time:  1.8  minutes.\n",
            "Embedding review: 1300\n",
            "Estimated remaining time:  1.7  minutes.\n",
            "Embedding review: 1320\n",
            "Estimated remaining time:  1.7  minutes.\n",
            "Embedding review: 1340\n",
            "Estimated remaining time:  1.6  minutes.\n",
            "Embedding review: 1360\n",
            "Estimated remaining time:  1.5  minutes.\n",
            "Embedding review: 1380\n",
            "Estimated remaining time:  1.5  minutes.\n",
            "Embedding review: 1400\n",
            "Estimated remaining time:  1.4  minutes.\n",
            "Embedding review: 1420\n",
            "Estimated remaining time:  1.4  minutes.\n",
            "Embedding review: 1440\n",
            "Estimated remaining time:  1.3  minutes.\n",
            "Embedding review: 1460\n",
            "Estimated remaining time:  1.3  minutes.\n",
            "Embedding review: 1480\n",
            "Estimated remaining time:  1.2  minutes.\n",
            "Embedding review: 1500\n",
            "Estimated remaining time:  1.1  minutes.\n",
            "Embedding review: 1520\n",
            "Estimated remaining time:  1.1  minutes.\n",
            "Embedding review: 1540\n",
            "Estimated remaining time:  1.0  minutes.\n",
            "Embedding review: 1560\n",
            "Estimated remaining time:  1.0  minutes.\n",
            "Embedding review: 1580\n",
            "Estimated remaining time:  0.9  minutes.\n",
            "Embedding review: 1600\n",
            "Estimated remaining time:  0.8  minutes.\n",
            "Embedding review: 1620\n",
            "Estimated remaining time:  0.8  minutes.\n",
            "Embedding review: 1640\n",
            "Estimated remaining time:  0.7  minutes.\n",
            "Embedding review: 1660\n",
            "Estimated remaining time:  0.7  minutes.\n",
            "Embedding review: 1680\n",
            "Estimated remaining time:  0.6  minutes.\n",
            "Embedding review: 1700\n",
            "Estimated remaining time:  0.5  minutes.\n",
            "Embedding review: 1720\n",
            "Estimated remaining time:  0.5  minutes.\n",
            "Embedding review: 1740\n",
            "Estimated remaining time:  0.4  minutes.\n",
            "Embedding review: 1760\n",
            "Estimated remaining time:  0.4  minutes.\n",
            "Embedding review: 1780\n",
            "Estimated remaining time:  0.3  minutes.\n",
            "Embedding review: 1800\n",
            "Estimated remaining time:  0.2  minutes.\n",
            "Embedding review: 1820\n",
            "Estimated remaining time:  0.2  minutes.\n",
            "Embedding review: 1840\n",
            "Estimated remaining time:  0.1  minutes.\n",
            "Embedding review: 1860\n",
            "Estimated remaining time:  0.1  minutes.\n",
            "Embedding review: 1880\n",
            "Time:  348.79667687416077 s\n",
            "Reviews are tokenized and put into vectors!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCBydAYEVT4T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b54e8c3-0a3b-4f05-fef7-75fa3b77f6bb"
      },
      "source": [
        "#Create good format for ontology\n",
        "#Change list1 to the location of bert vectors\n",
        "start = time.time()\n",
        "list1 = bert_vectors\n",
        "words = {}\n",
        "j=1\n",
        "counterRev = 0\n",
        "for rev in list1:\n",
        "    counterRev += 1\n",
        "    for word in rev:\n",
        "        string1 = str(word[0])\n",
        "        words[j] = {'word': string1,\n",
        "                    'vector': word[1]\n",
        "                    ,'sentence id': word[2]\n",
        "                   }\n",
        "        j = j+1\n",
        "        \n",
        "print('Number of reviews done: ', counterRev, ', with ', j, ' words in total.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of reviews done:  1900 , with  106957  words in total.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nclC9GU5VT4U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a625401-2154-4895-b7b2-9590a1c51ee9"
      },
      "source": [
        "#Save file\n",
        "name_file = \"T5FT.txt\"\n",
        "\n",
        "import json\n",
        "start = time.time()\n",
        "with open(name_file, 'w') as outfile:\n",
        "    json.dump(words, outfile)\n",
        "end = time.time()\n",
        "print(\"Time: \", end-start, \"s\")\n",
        "print(\"Vectors are saved in \" + name_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time:  167.4676809310913 s\n",
            "Vectors are saved in T5FT.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufKy0nLGVT4U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "705af570-5901-4ff0-dd12-e1a0759122a9"
      },
      "source": [
        "# Remove everything from memory\n",
        "import gc\n",
        "del words\n",
        "del bert_vectors\n",
        "del list1\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4LwoNj0VT4U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}